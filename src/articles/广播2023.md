---
title: 2022广播
author: yizhi
slug: guangbo-2023
date: 2023-12-31 
stack: modal
---
03-07
- 看了看「ControlNet」、「LoRA」、「ChilloutMix」，Orz……
- 试了试Colab + Stable Diffusion web UI

03-05
- 复习了一下react，还是[官方文档](https://beta.reactjs.org/reference/react/useCallback)清楚一些，就是太长了。

03-01
- 看了篇讲「[Word Embedding](https://zhuanlan.zhihu.com/p/49271699?utm_id=0)」的。
- 「[LLM](https://zhuanlan.zhihu.com/p/597586623)」
- 「[Locating and Editing Factual Associations in GPT](https://rome.baulab.info/)」

02-28
- 我以为的图：{NodeA: NodeB, NodeC}，实际上也可以：{Edges: NodeA, NodeB}
- GPT为什么知道什么时候结束呢？因为「end itself is a word/vector」 
- GPT为什么可以self-learning呢？因为任意一句话的切片p[i:j]的下一个词就包含在p[i+1:j+1]里了，直接交叉墒desu。
- 补充一个读论文「[COT](https://www.bilibili.com/video/BV1t8411e7Ug/)」

02-27
- 终于把之前搁置的课程看完了，长篇小说。
- 「[Self-attention](https://www.youtube.com/watch?v=hYdO9CscNes)」、「[Transformer](https://www.youtube.com/watch?v=n9TlOhRjYoc)」、「[Transformer读论文](https://www.bilibili.com/video/BV1pu411o7BE)」、「[GPT读论文](https://www.bilibili.com/video/BV1AF411b7xQ/)」、「[GPT in 60 Lines of NumPy](https://jaykmody.com/blog/gpt-from-scratch/)」

02-25
- 大概确定以前想实现的「[softbody](https://twitter.com/JuhaniHalkomaki/status/1626327846032404480)」效果用的方法是PositionBasedDymnamic，但并不意味着会写。

02-17
- 合并两个有序链表的递归解法好像伏羲女娲图。

02-16
- 小时候当不了祖国的花朵，长大可以当祖国的花圈。
- 小时候淋过雨，长大要烧了全世界的伞。

02-12
- [「翻新着隐喻与字面之间的摩擦系数」](https://book.douban.com/review/6132267/)
- [2022广播归档](./douban/guangbo-2022)

02-01
- 刚刚听一张氛围音乐专辑，感叹其鼓点如同水汽氤氲一般，若隐若现，潮湿而富有弹性。后来发现是我保温瓶没关紧……

